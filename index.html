<!doctype html>
<html>

<head>
  <title>Mustafa Bhadsorawala</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-103598896-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" id="me" src="img/me.JPG">
          </div>
          <div class="flex-item flex-column">
            <h2>Mustafa Bhadsorawala</h2>
            <p class="text">
              Robotics Engineer<br>
              mustafabhadsorawala (at) gmail.com<br>
              mb8595 (at) nyu.edu<br>
              <a href="https://engineering.nyu.edu/academics/robotics" target="_blank">MS Mechatronics and Robotics</a><br>
              <a href="https://engineering.nyu.edu/" target="_blank">New York University</a>, New York<br>
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2>Biography</h2>
            <hr>
            <p class="text">
              I'm a <b>robotics engineer,</b> with interests in domestic service robots. My interests lie in Optimal Control, Mechatronics and programming. I have practical experience in applying fundamental
              concepts of perception and localization systems. I have worked on a variety of projects, including a <a href="https://youtu.be/_hx9OF3YN0M" target="_blank">Indoor Localization using FTM and IMU</a> for my capstone project.
            </p>
            <p class="text">
              In my project, I developed an IMU-based pedestrian dead reckoning system and fused the data with an FTM EKF algorithm to improve the localization accuracy. The project involved programming in Python and C++, hardware integration, and testing in real-world scenarios.
            </p>
            <p class="text">
              I am a Gradute Teaching assistant at the <a href="http://engineering.nyu.edu/mechatronics/index.html" target="_blank">Mechatronics, Controls and Robotics lab</a>, <a href="https://engineering.nyu.edu/" target="_blank">New York University</a>.
              I am pursuing my graduate <b>MS in Mechatronics, Robotics</b> at NYU, and I specialize in Mobile robotics and Controls.
              Before NYU, I was a Product Development Engineer at <a href="https://baarilabs.com/" target="_blank">Baari Labs</a> a 3D printing and rapid prototyping startup in Indore, India.
              Previously, I started a additive manufacturing business, offering, FDM, SLA manufacturing and CAD modelling services.
              I earned my Bachelor's degree in <a href="https://kjsce.somaiya.edu/en" target="_blank">Mechanical Engineering</a>, I minored in robotics and built an afforadable bionic arm that won the 1st prize.
            </p>
            <!-- <p class="text">
              About my name, my given name is Yen-Chia, not Yen.
              My English name (Yen-Chia Hsu) comes from the Wade-Giles transcription of my name in Traditional Mandarin Chinese.
              In Taiwan, when using the Wade-Giles transcription system, we put a dash between our given name's characters.
              Also, in Traditional Mandarin Chinese, we put the family name before the given name, which is different from the English naming conventions.
              For pronunciation, Yen is like the Japanese yen, and Chia is like "ja" when saying Ninja.
              My family name (Hsu) is hard to pronounce since the English system does not have such types of vocalization.
              The closest sound is "she," not "su."
            </p> -->
            <h3>Table of Content</h3>
            <ul>
              <li><a href="#award">Awards and Honors</a></li>
              <!-- <li><a href="#journal-paper">Referred Journal and Magazine Papers</a></li> -->
              <!-- <li><a href="#conference-paper">Referred Conference Papers</a></li> -->
              <li><a href="#wip-paper">Referred Posters, Works-in-Progress, and Workshop Paper</a></li>
              <!-- <li><a href="#other-paper">Other Publications</a></li> -->
              <!-- <li><a href="#feature-media">Featured Media and Book Coverage</a></li> -->
              <li><a href="#other-media">Other Media</a></li>
              <!-- <li><a href="#tool">Released Open Source Tools</a></li> -->
              <li><a href="#teaching">Teaching</a></li>
              <li><a href="#project">Projects</a></li>
            </ul>
            <h2 id="award">Awards and Honors</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication A-list">
              <li>
                <p class="text-small-margin">
                  Top 10 in pan-India for Mechatronic Earthworm.
                  2016. Aakruti Design Competition, 3DPLM and Dassault Systems, India.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  First Prize, Best BE Project.
                  2017. New York Universtity, India.
                </p>
              </li>
            </ol>
            <!-- <h2 id="journal-paper">Referred Journal and Magazine Papers</h2>
            <hr>
            <ol class="publication J-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b> and Illah Nourbakhsh. 2020. When Human-Computer Interaction Meets Community Citizen Science. Communications of the ACM.
                  <br>
                  <a href="file/ccs.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://doi.org/10.1145/3376892" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1907.11260" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://cacm.acm.org/magazines/2020/2/242344-when-human-computer-interaction-meets-community-citizen-science/fulltext" target="_blank">Webpage</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Michael Tasota, Beatrice Dias, Randy Sargent, Ting-Hao Huang, and Illah Nourbakhsh. 2020. Smell Pittsburgh: Engaging Community Citizen Science for Air Quality. ACM Transactions on Interactive Intelligent Systems.
                  <br>
                  <a href="file/smell-pgh-journal.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://dl.acm.org/doi/10.1145/3369397" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1912.11936" target="_blank">Preprint</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Himanshu Verma, Andrea Mauri, Illah Nourbakhsh, and Alessandro Bozzon. 2022. Empowering local communities using artificial intelligence. Patterns, 3(3), 100449.
                  <br>
                  <a href="https://doi.org/10.1016/j.patter.2022.100449" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2110.02007" target="_blank">Preprint</a>
                </p>
              </li>
            </ol>
            This list is reversed on the website due to reverse number listing-->
            <!-- <h2 id="conference-paper">Referred Conference Papers</h2>
            <hr> -->
            <!--This list is reversed on the website due to reverse number listing-->
            <!-- <ol class="publication C-list">
              <li>
                <p class="text-small-margin">
                  Yang-Ting Shen, Tay-Sheng Jeng, and <b>Yen-Chia Hsu</b>. 2011. A "Live" Interactive Tagging Interface for Collaborative Learning. International Conference on Cooperative Design, Visualization and Engineering (CDVE 2011). Springer.
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007%2F978-3-642-23734-8_16" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">Blog</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Tay-Sheng Jeng, Yang-Ting Shen, and Po-Chun Chen. 2012. SynTag: A Web-based Platform for Labeling Real-time Video. In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work (CSCW 2012). ACM.
                  <br>
                  <a href="file/syntag.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="http://dl.acm.org/citation.cfm?id=2145312" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=k7zWjvpDYtE" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/SynTag" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Paul Dille, Jennifer Cross, Beatrice Dias, Randy Sargent, and Illah Nourbakhsh. 2017. Community-Empowered Air Quality Monitoring System. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM.
                  <span class="custom-text-danger">(Best Paper Honorable Mention Award, Top 5%)</span>
                  <br>
                  <a href="file/community-empowered-air-quality-monitoring-system.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="http://dl.acm.org/citation.cfm?id=3025853" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1804.03293" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=WxOw0j3oTXM" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/02/02/community-empowered-air-quality-monitoring-system-acm-chi-2017-full-paper/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/ACCAN-survey.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="http://shenangochannel.org/" target="_blank">Website</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/the-shenango-channel" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Michael Tasota, Beatrice Dias, Randy Sargent, Ting-Hao (Kenneth) Huang, and Illah Nourbakhsh. 2019. Smell Pittsburgh: Community-Empowered Mobile Smell Reporting System. In Proceedings of the 24th International Conference on Intelligent User Interfaces (IUI 2019). ACM.
                  <span class="custom-text-danger">(Best Paper Honorable Mention Award, Top 2.5%)</span>
                  [Note: this paper has errors, and we provide the corrections in the last two pages of the preprint]
                  <br>
                  <a href="file/smell-pgh.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://dl.acm.org/citation.cfm?id=3302293" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1810.11143" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=aOPyPfjJhBs" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=JNbGIhK_lx8" target="_blank">Conference Talk</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/07/10/smell-pgh-a-mobile-application-to-crowdsource-and-visualize-pollution-odors/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/smell-pgh-survey.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://smellpgh.org/" target="_blank">Website</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/smell-pittsburgh-prediction" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Yao Hsu, Chieh-Yang Huang, <b>Yen-Chia Hsu</b>, and Ting-Hao Huang. 2019. Visual Story Post-Editing. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics (ACL 2019).
                  <br>
                  <a href="http://dx.doi.org/10.18653/v1/P19-1658" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1906.01764" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/tingyaohsu/VIST-Edit" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Ting-Hao (Kenneth) Huang, Ting-Yao Hu, Paul Dille, Sean Prendi, Ryan Hoffman, Anastasia Tsuhlares, Jessica Pachuta, Randy Sargent, and Illah Nourbakhsh. 2021. Project RISE: Recognizing Industrial Smoke Emissions. Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2021).
                  <br>
                  <a href="file/project-rise.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17739" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2005.06111" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/deep-smoke-machine" target="_blank">Code and Data</a>
                </p>
              </li>
            </ol> -->
            <!-- <h2 id="wip-paper">Referred Posters, Works-in-Progress, and Workshop Paper</h2>
            <hr>-->
            
            <!--This list is reversed on the website due to reverse number listing-->
            
            <!--<ol class="publication P-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Paul Dille, Randy Sargent, Christopher Bartley, and Illah Nourbakhsh. 2015. A Web-based Large-scale Timelapse Editor for Creating and Sharing Guided Video Tours and Interactive Slideshows. IEEE Information Visualization Posters, 2015.
                  <br>
                  <a href="file/timelapse-editor.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://vimeo.com/136251467" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/14/a-web-based-large-scale-timelapse-editor-for-creating-and-sharing-guided-video-tours-and-interactive-slideshows-ieee-vis-2015-poster/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/timemachine-viewer" target="_blank">Code and Data</a>
                </p>
              </li>
             <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Illah Nourbakhsh, Leann Leiter, and Ryan Grode. 2018. Visualization Tool for Environmental Sensing and Public Health Data. In Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems (DIS 2018 Companion). ACM.
                  <br>
                  <a href="file/env-health-channel.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://dl.acm.org/citation.cfm?id=3197391.3205419" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1804.03263" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/08/31/environmental-health-channel-an-online-tool-for-visualizing-sensor-and-health-data/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/env-health-channel-focus-group-questions.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://envhealthchannel.org/" target="_blank">Website</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/ehp-channel" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Yao Hsu, <b>Yen-Chia Hsu</b>, and Ting-Hao (Kenneth) Huang. 2019. On How Users Edit Computer-Generated Visual Stories. In Extended Abstracts of the 2019 CHI Conference on Human Factors in ComputingSystems (CHI EA 2019). ACM.
                  <br>
                  <a href="https://dl.acm.org/citation.cfm?id=3312965" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1902.08327" target="_blank">Preprint</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Hao (Kenneth) Huang, Chieh-Yang Huang, Chien-Kuang Cornelia Ding, <b>Yen-Chia Hsu</b>, and C. Lee Giles. 2020. CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the COVID-19 Open Research Dataset. In Proceedings of the 1st Workshop on NLP for COVID-19 at Association for Computational Linguistics (ACL 2020).
                  <br>
                  <a href="https://www.aclweb.org/anthology/2020.nlpcovid19-acl.6/" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2005.02367" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/windx0303/CODA-19" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Andrea Mauri, Andrea Tocchetti, Lorenzo Corti, <b>Yen-Chia Hsu</b>, Himanshu Verma, and Marco Brambilla. 2022. COCTEAU: an Empathy-Based Tool for Decision-Making. Posters and Demos Track at The Web Conference 2022 (WWW 2022).
                  <br>
                  <a href="https://arxiv.org/abs/2204.06289" target="_blank">Preprint</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Andrea Mauri, <b>Yen-Chia Hsu</b>, Marco Brambilla, Aisling Ann O'Kane, Ting-Hao (Kenneth) Huang, and Himanshu Verma. 2022. Empathy-Centric Design At Scale. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA 2022). ACM.
                  <br>
                  <a href="https://dl.acm.org/doi/10.1145/3491101.3503744" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2204.06382" target="_blank">Preprint</a>
                </p>
              </li>
            </ol> -->
            <!-- <h2 id="other-paper">Other Publications</h2>
            <hr> -->
            <!--This list is reversed on the website due to reverse number listing-->
            <!-- <ol class="publication O-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2016. Industrial Smoke Detection and Visualization. Technical Report CMU-RI-TR-16-55. Robotics Institute, Carnegie Mellon University, Pittsburgh, PA.
                  <br>
                  <a href="file/industrial-smoke-detection-and-visualization.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.ri.cmu.edu/publications/industrial-smoke-detection-and-visualization/" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/industrial-smoke-detection" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2018. SimArch: A Multi-agent System For Human Path Simulation In Architecture Design. arXiv preprint arXiv:1807.03760.
                  <br>
                  <a href="https://arxiv.org/abs/1807.03760" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/SimArch" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Emiliano Huet-Vaughn, Nicholas Muller, and <b>Yen-Chia Hsu</b>. 2018. Livestreaming Pollution: A New Form of Public Disclosure and a Catalyst for Citizen Engagement. No. w24664. National Bureau of Economic Research, 2018.
                  <br>
                  <a href="http://www.nber.org/papers/w24664" target="_blank">Preprint</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2018. Designing Interactive Systems for Community Citizen Science. Ph.D. Dissertation. Robotics Institute, Carnegie Mellon University, Pittsburgh, PA.
                  <br>
                  <a href="https://www.ri.cmu.edu/wp-content/uploads/2018/08/yc_hsu_robotics_2018.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://figshare.com/articles/Designing_Interactive_Systems_for_Community_Citizen_Science/7195082/1" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.ri.cmu.edu/publications/designing-interactive-systems-for-community-citizen-science/" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=QOFfCD8r240" target="_blank">Video</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2021. 社區公民科學: 用開放數位平台的技術與公民合作解決都市環境問題. 眼底城事.
                  <br>
                  <a href="https://eyesonplace.net/2021/03/19/16600/?fbclid=IwAR1BGVj4_j385ApEYIjtYpdN6UM_0Fx7llPCJqV2KoBvYHWFB-azvPwMNAk" target="_blank">Source</a>
                </p>
              </li>
            </ol> -->
            <!-- <h2 id="feature-media">Featured Media and Book Coverage</h2>
            <hr> -->
            <!--This list is reversed on the website due to reverse number listing-->
            <!-- <ol class="publication F-list">
              <li>
                <p class="text-small-margin">
                  <b>TIME</b>. Jeffrey Kluger. 2013.
                  <a target="_blank" href="http://world.time.com/timelapse/">Timelapse: Landsat Satellite Images of Climate Change</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Pittsburgh Post-Gazette</b>. Ashley Murray. 2017.
                  <a target="_blank" href="http://www.post-gazette.com/business/tech-news/2017/07/03/smell-pgh-app-carnegie-mellon-university-cmu-create-lab-foul-smell-pittsburgh/stories/201706300430">Carnegie Mellon Scientists Use App to Track Foul Odors in Pittsburgh</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>PC Magazine</b>. Michelle Donahue. 2018.
                  <a target="_blank" href="https://www.pcmag.com/article/360317/citizen-science-do-try-this-at-home">Citizen Science: Do Try This at Home</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Pittsburgh Earth Day</b>. Amanda Waltz. 2021.
                  <a target="_blank" href="https://pittsburghearthday.org/partnership-wins-award-for-using-tech-to-track-pittsburgh-air-pollution/">Partnership Wins Award for Using Tech to Track Pittsburgh Air Pollution</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a target="_blank" href=""></a>
                  <br>in by (2016)
                </p>
              </li>
            </ol> -->
          
            <!--Start Teaching and Projects-->
          <div class="flex-row full-width">
            <div class="flex-item flex-column full-width">
              <h2 id="teaching">Teaching</h2>
              <hr>
              <ul>
                <li>
                  <a href="https://multix.io/data-science-book-uva/" target="_blank">Data Science</a>, 2022/2023, University of Amsterdam
                </li>
              </ul>
              <h2 id="project">Projects</h2>
              <hr>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/cocteau.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">COCTEAU: an Empathy-Based Tool for Decision-Making [P5, P6, T14], 2021 - 2022</span><br>
                I worked in a team to build a tool to strengthen interactions between citizens and decision-makers on a large scale.
                The goal is to elicit empathetic relations among stakeholders to collect perspectives on societal issues.
                (<a href="https://periscope.io.tudelft.nl/" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/smoke-labeling.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Project RISE: Recognizing Industrial Smoke Emissions [C6, T13], 2018 - 2020</span><br>
                I co-designed a system with local communities in labeling videos with industrial smoke emissions.
                These labels were used to train a deep neural network to recognize smoke and industrial pollution events for air quality advocacy.
                (<a href="https://smoke.createlab.org/" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/earthtime-editor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">A Tool for Creating Interactive Stories on the EarthTime Timelapse [T10], 2018</span><br>
                I worked in a team to develop a web-based tool that enables users to create, edit, and share
                stories about nature changes and human impact on EarthTime, visualizing the transformation of
                the EarthTime over three decades with images and datasets.
                (<a href="https://earthtime.org" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/smell-pgh.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2017/07/10/smell-pgh-a-mobile-application-to-crowdsource-and-visualize-pollution-odors/" target="_blank">Community-Empowered Mobile Smell Reporting System [C4, F2, T9, A6], 2017 - 2018</a></span><br>
                I worked in a team to develop Smell Pittsburgh, a mobile application for citizens to report pollution odors to regulators.
                A map visualizes the reports with air quality and wind data.
                A machine learning model predicts odors and sends push notifications.
                (<a href="http://smellpgh.org" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/env-health-channel.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2017/08/31/environmental-health-channel-an-online-tool-for-visualizing-sensor-and-health-data/" target="_blank">Visualization Tool for Environmental Sensing and Public Health Data [P2, T5, T8], 2017</a></span><br>
                I worked in a team to develop the Environmental Health Channel, an interactive web-based tool for visualizing health symptoms, particulate measurements, and personal stories from residents who are affected by oil and gas drilling development.
                (<a href="http://envhealthchannel.org" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/air-quality-monitor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2017/02/02/community-empowered-air-quality-monitoring-system-acm-chi-2017-full-paper/" target="_blank">Community-Empowered Air Quality Monitoring System [C3, F3, A5], 2015 - 2016</a></span><br>
                I worked with local citizens to build an air quality monitoring system that integrates camera data, sensing data, and smell reports.
                The system used computer vision to generate videos with smoke emissions to serve as evidence of pollution.
                (<a href="http://shenangochannel.org/" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/timelapse-editor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/14/a-web-based-large-scale-timelapse-editor-for-creating-and-sharing-guided-video-tours-and-interactive-slideshows-ieee-vis-2015-poster/" target="_blank">A Web-based Large-scale Timelapse Editor for Interactive Storytelling [P1, T7], 2014</a></span><br>
                Based on the timelapse viewer, I developed a tool for users to create interactive slideshows or guided tours.
                Users can embed or share the slideshows or tours on social media for telling interactive stories.
                (<a href="http://timemachine.cmucreatelab.org/wiki/EarthEngineTourEditor" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/timelapse-viewer.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/13/earth-timelaspe-viewer-visualizing-landsat-satellite-imagery-webby-peoples-voice-award-2014/" target="_blank">Earth Timelaspe Viewer Visualizing Landsat Satellite Imagery [F1, T7, A4], 2013</a></span><br>
                I worked in a team to develop an Earth timelapse viewer, consisting of cloud-free mosaics of the planet with billions of pixels for decades.
                The interactive viewer was released with Google and TIME.
                (<a href="https://earthengine.google.com/timelapse/" target="_blank">link to Google Earth Engine</a>, <a href="http://world.time.com/timelapse/" target="_blank">link to TIME</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/simarch.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/11/simarch-a-multi-agent-system-for-human-path-simulation-in-architecture-design/" target="_blank">SimArch: A Multi-Agent System for Human Path Simulation [O2, T2], 2012</a></span><br>
                SimArch uses Markov Decision Process to build a behavior model.
                The model simulates mental states, target range detection, and collision prediction when agents behave in a museum.
                SimArch outputs the prediction of how likely a person will occur in a location after simulation.
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/senseable-shoes.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/09/senseable-shoes-hands-free-and-eyes-free-mobile-interaction/" target="_blank">SENSEable Shoes: Hands-Free and Eyes-Free Mobile Interaction [T3], 2012</a></span><br>
                SENSEable Shoes is a platform for interaction designers to create applications.
                It recognizes low-level activities by measuring the weight distribution over the feet with sensors in the shoe pad.
                A Support Vector Machine classifier identifies mobile activities and foot gestures.
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/drawolin.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/08/draw-o-lin-a-music-visualizer-for-violin/" target="_blank">Draw-o-lin: A Music Visualizer for Violin, 2011</a></span><br>
                What does music look like?
                Draw-o-lin is an interactive mobile robot visualizing music by drawing graphs on a paper according to various sound properties.
                Violin performers control the robot by playing various pitches, alternating the volume, and changing the tempo.
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/syntag.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text"><a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">SynTag: A Web-Based Platform for Labeling Real-time Video [C2, C1, T1], 2010</a></span><br>
                Users can label Good, Question, and Disagree tags in real or non-real time with visualization of time-stamp video previews on an interactive timeline.
                SynTag creates thumbnails by using real-time tags for presenters to receive instant feedback and for others to retrieve videos.
              </p>
            </div>
          </div>
          <!--End Projects-->
        </div>
      </div>
    </div>
  </div>
</body>

</html>